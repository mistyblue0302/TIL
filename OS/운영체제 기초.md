## 운영체제와 커널

- 운영체제란 컴퓨터 하드웨어 바로 위에 설치되어 사용자 및 다른 모든 소프트웨어와 하드웨어를 연결하는 소프트웨어 계층
- 컴퓨터 시스템의 **자원을 효율적으로 관리**
  - 중앙 처리 장치(CPU), 기억장치, 입출력 장치 등의 효율적 관리
  - 실행중인 프로그램들에게 CPU를 번갈아 할당, 메모리 공간을 적절히 분배
- 컴퓨터 시스템을 편리하게 사용할 수 있는 환경을 제공

그렇다면 운영체제는 어디에 위치해 있길래 모든 시스템 자원을 관리하고 제어하는 것일까? 사실 운영체제도 디스크에 저장되어 있다가 실행할 시기가 오면, 메모리에 올라와서 실행되어 사용자 인터페이스를 제공해준다. 운영체제는 우선순위가 높을 뿐 하나의 소프트웨어이기 때문이다.

하지만 운영체제의 용량은 매우 크다. 그렇기 때문에 메모리에 모두 올라와 실행하기에는 비효율적이다. 그렇다면 어떻게 해야할까? 정말 필요한 것들만 메모리에 올리면 된다. 이렇게 **메모리에 올라간 운영체제의 특정 부분**을 **커널**이라고 한다.

커널은 아래와 같은 기능을 수행한다.

- 프로세스 관리 및 CPU 스케줄링
  - 프로세스마다 CPU를 사용할 수 있는 시간을 분배 및 관리한다. 
- 한정된 메모리를 어떻게 쪼개어 쓸지 메모리 관리
- 각기 다른 입출력장치와 컴퓨터 간에 어떻게 정보를 주고 받을지 입출력 관리
- 디스크에 파일을 어떻게 보관할지 파일관리

![img](https://github.com/dilmah0203/TIL/blob/main/Image/computer%20architecture2.png)

- **CPU가 수행해야 할 명령의 메모리 주소를 담고 있는 레지스터**를 **프로그램 카운터**라고 한다.
- 메모리에는 사용자 프로그램들과 운영체제가 같이 올라가 수행되는데, 이때 CPU는 프로그램 카운터가 가리키는 메모리 위치의 프로그램을 수행한다.
- 프로그램 카운터가 운영체제를 가리키고 있으면 **커널 모드**, 프로그램 카운터가 프로그램을 가리키고 있으면 **사용자 모드** 이다.

CPU가 수행하는 명령에는 메모리에서 자료를 읽어와 CPU에서 연산하고 결과를 메모리에 쓰는 **일반명령**과 보안이 필요한 명령으로 입출력 장치, 타이머등에 접근하는 **특수명령**이 있다. CPU내의 모드비트를 이용하여 시스템은 실행가능성을 체크한다. 다만 사용자 프로그램을 실행하다가 특수명령이 필요할때가 생기게 된다. 이때는 사용자 프로그램이 스스로 특수명령을 실행할 수 없기에 **시스템 콜**이라는 서비스 요청을 하여 운영체제에게 대행을 요구한다. 

**시스템 콜**을 하게 되면 운영체제는 사용자 프로그램의 코드가 아닌 **커널 영역에 정의된 시스템 콜 처리 코드를 수행**하게 된다. **즉, 커널은 시스템 콜이 발생하면 CPU를 커널 모드로 전환하여 자신들의 작업을 수행한다.**

사용자와 운영체제는 시스템 자원을 공유하기 때문에 사용자에 제한을 두지 않으면 메모리 내 주요 자원을 망가뜨릴 위험이 있다. 따라서 사용자의 자원 접근을 막는 보호 장치가 필요하고, 이것이 이중 동작 모드이다. 이중 동작 모드는 사용자가 접근할 수 없는 **커널 모드**, 접근할 수 있는 **사용자 모드**로 나뉜다.

![img](https://github.com/dilmah0203/TIL/blob/main/Image/Interrupt%20Service%20Routine2.png)

- 프로세스는 사용자 모드에서 실행되다가 운영체제에게 시스템 사용을 요청하면 커널 모드로 전환되어 요청된 시스템을 실행한 후 다시 사용자 모드로 전환한다. (시스템 콜) 
- 시스템 콜은 하나의 인터럽트로 취급된다. 커널 모드와 사용자 모드를 구분하기 위해서는 mode bit가 사용되며 0이 커널 모드, 1이 사용자 모드이다.
- 운영체제는 일부 명령들을 특권 명령으로 지정하고 커널 모드에서만 실행되게 하며 사용자 모드에서 실행하려고 하면 trap을 건다.
- 사용자 모드에서 실행되는 프로세스들은 서로 간에 메모리 등의 자원을 공유하지 않지만, 커널 모드는 프로세스 간에 공유되는 시스템 자원을 관리한다.
  
## 프로그램의 실행

**프로그램이 실행되고 있다는 것**은 **디스크에 존재하던 실행파일이 메모리에 적재**되거나 **프로그램이 CPU를 할당 받고 명령을 수행하고 있는 상태**라는 것이다.

![img](https://github.com/dilmah0203/TIL/blob/main/Image/program.png)

- **프로그램**은 보통 실행파일 형태로 하드디스크에 저장되고 실행파일을 실행시키면 메모리로 올라가 **프로세스**가 된다.
- 메모리로 올라가기 전, 운영체제는 각 프로그램에 대해 가상 메모리 주소 공간을 할당하는 과정을 거치게 되는데 **가상메모리**의 주소 공간은 **코드, 데이터, 스택** 등으로 구성된다.
- 각 프로그램마다 이러한 가상 메모리 주소공간을 별도로 가지고 이것을 물리적인 메모리로 올려 실행시키게 된다. 물리적인 메모리 공간의 커널은 처음 부팅 시 항상 상주하여 올라가있지만 사용자 프로그램들은 이후 프로세스가 종료되면, 해당 가상 메모리 주소 공간은 운영체제에 의해 해제된다.

![img](https://github.com/dilmah0203/TIL/blob/main/Image/program2.png)

- 운영체제의 커널 또한 **코드, 데이터, 스택 공간**을 가진다.
- **커널의 코드 영역**에는 CPU, 메모리 등의 자원을 관리 하기 위한 부분과 시스템 콜 및 인터럽트를 처리하는 부분을 포함한다.
- **커널의 데이터 영역**에는 각종 자원(CPU, 메모리, 프로그램 등)을 관리하기 위한 자료구조가 저장된다.
- **커널의 스택 영역**에는 현재 수행 중인 프로세스마다 별도의 스택을 두어 관리한다. 

## 시분할(time sharing) 처리 방식

- 현대 운영체제에서 사용하는 방식이다.
- 여러 작업을 수행할 때 CPU를 사용하는 시간을 잘개 쪼개서, 여러 응용 프로그램이 동시에 실행되는 것처럼 보이게 하는 기법
- 다중 사용자를 지원하고, 일괄 처리 시스템에 비해 짧은 응답 시간을 가짐
- 멀티 태스킹
  - 단일 CPU에서, 여러 응응 프로그램이 동시에 실행되는것처럼 보이도록 하는 시스템
- 멀티 프로그래밍
  - 최대한 많은 CPU를 활용하도록 하는 시스템
- 멀티 프로세싱
  - 여러 CPU에서 하나의 응용 프로그램을 병렬로 실행해서 속도를 높이는 기법

## 인터럽트

**인터럽트**란 **CPU가 프로그램을 실행하고 있을때, 입출력 하드웨어 등의 장치(이벤트 발생)나 예외상황이 발생하여 처리가 필요한 경우 CPU에 알려주는 처리 기술**이다.

CPU는 매번 프로그램 카운터가 가리키고 있는 지점의 명령을 하나씩 수행하고 나서, 다음 명령을 수행하기 직전에 인터럽트 라인이 세팅되어있는지 체크한다. 인터럽트 라인 체크를 통해 인터럽트가 발생했다면 CPU는 현재 수행중인 프로세스를 멈추고 **CPU를 운영체제가 회수 및 인터럽트 처리루틴으로 이동하여** 커널 모드에서 인터럽트 처리를 수행한다. 인터럽트의 처리를 마치고 나면 인터럽트가 발생하기 직전의 프로세스에게 CPU의 제어권이 다시 넘어간다.

![img](https://github.com/dilmah0203/TIL/blob/main/Image/interrupt.png)

## 프로세스

![img](https://github.com/dilmah0203/TIL/blob/main/Image/process1.png)
 
- 실행 중인 프로그램을 프로세스라고 함
  - 프로세스 : 메모리에 올려져서, 실행 중인 프로그램
  - 코드 이미지(바이너리): 실행 파일, 예
- 프로세스는 각각 독립된 메모리 영역을 할당 받는다 (Code, Data, Stack, Heap)
- 기본적으로 프로세스당 최소 1개의 쓰레드(메인 쓰레드)를 가지고있다.
- 각 프로세스는 별도의 주소 공간에 실행되며, 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없다.
- 프로세스 간의 자원을 공유를 하기 위해서는 IPC(InterProcess Communication : 프로세스 간 협력 메커니즘) 기법을 이용해야한다.
  - 메세지 큐, 세마포어, 소켓 등이 있다.

![img](https://github.com/dilmah0203/TIL/blob/main/Image/process2.png)

- New : 프로세스가 생성된 상태로 PCB가 생성되어도 보조 메모리에 존재한다.
- Ready : 실행을 하기 위해 기다리는 상태. CPU를 할당해주면 바로 실행한다.
- Running : 프로세스가 CPU를 차지하고 실행하고 있는 상태
- Blocked : CPU를 할당해주어도 실행할 수 없는 상태(I/O resquest, 다른 프로세스가 끝날 때까지 대기)
- Exit : 프로세스가 끝나고 할당 받았던 자원들을 반납한다.

## 문맥 교환

- CPU를 한 프로세스에서 다른 프로세스로 넘겨주는 과정
- CPU가 다른 프로세스에게 넘어갈 때 운영체제는 다음을 수행
  - CPU를 내어주는 프로세스의 상태를 커널 주소 공간의 data 영역의 PCB에 저장
  - CPU를 새롭게 얻는 프로세스의 상태를 PCB에서 읽어옴 → 마지막으로 실행했던 곳부터 찾아서 작업할 수 있도록

## 쓰레드

- 프로세스 내에서 할당받은 자원을 이용해 동작하는 작업 단위
- 쓰레드는 프로세스 내에서 각각 Stack만 따로 할당받고 Code, Data, Heap 영역은 공유한다.
- 멀티 쓰레드
  - 하나의 쓰레드가 blocked(waiting) 상태인 동안에도 다른 쓰레드가 실행되어 빠른 처리를 할 수 있다.
  - 동일한 일을 수행하는 다중 쓰레드가 협력하여 높은 처리율과 성능 향상을 얻을 수 있다. 

## PCB

![img](https://github.com/dilmah0203/TIL/blob/main/Image/PCB.png)

- 운영체제가 각 프로세스를 관리하기 위해 프로세스당 유지하는 정보
- 다음의 구성 요소를 가진다.
  - 프로세스 ID와 상태
  - 프로그램 카운터, 레지스터 정보 
  - CPU 스케줄링 정보, 코드, 데이터, 스택의 위치 정보
- TCB : PCB 내에서 쓰레드를 관리하는 자료구조

쓰레드는 프로세스마다 가지고 있는 정보 PCB에서 CPU수행과 관련된 정보를 각각의 쓰레드가 별도로 가지고 있다. 위 예시는 하나의 프로세스 내에서 2개의 쓰레드가 추가 생성되어 총 3개의 쓰레드가 독립적으로 실행되는 중이다.

## CPU 스케쥴링 알고리즘

- 프로세스 실행을 관리하는 것이 스케쥴러
- CPU 이용률은 높게, 프로세스 응답 시간을 가능한 짧게 주어진 시간에 많은 프로세스를 하는 것을 목표로 한다.
- 비선점형 스케쥴링
  - FCFS(First Come, First Served) : 가장 먼저 요청한 프로세스에 CPU를 할당
  - SJF(Shortest Job First) : 실행 시간이 가장 짧은 프로세스를 먼저 실행
  - Priority : 각각의 프로세스에 우선순위가 있는 알고리즘
- 선점형 스케쥴링
  - RR(Round Robin) : 각각의 프로세스에 동일한 할당 시간을 부여해서 해당 시간 동안만 CPU를 이용
  - SRF(Shortest Remaining Time) : 중간에 더 짧은 작업이 들어오면 수행하던 프로세스를 중지하고 프로세스를 수행
  - Multilevel Queue : 우선순위에 따른 준비 큐가 여러 개의 큐들로 나뉘고 각각의 큐는 각자의 스케줄링 알고리즘을 가지고 있다. 우선순위가 높은 큐부터 처리되기 때문에 낮은 큐의 프로세스가 처리가 안되는 기아현상이 나타날 수 있다.
 
## Race Condition(경쟁상태)

**경쟁상태**는 **여러 프로세스들이 동시에 공유 데이터를 접근하는 상황**으로 데이터의 불일치 문제를 발생시킬 수 있다.

- **커널 실행 중에 인터럽트가 발생할 경우**
  - 커널모드에서 데이터를 로드하여 작업을 하던 도중 인터럽트가 발생하여 인터럽트 처리루틴이 수행
  - 양쪽 다 커널 코드이므로 커널 주소 공간을 공유
  - 해결 방법 : 커널모드에서 작업을 수행하는 동안 인터럽트를 disable시켜 인터럽트가 CPU 제어권을 가져가지 못하도록 하여 해결할 수 있다.

![img](https://github.com/dilmah0203/TIL/blob/main/Image/race%20condition.png)


- **프로세스가 시스템 콜을 하여 커널모드로 진입해서 작업을 수행하는 도중에 문맥 교환이 발생할 경우**
  - 프로세스A가 커널모드에서 데이터를 조작하던 도중 시간이 초과되어 CPU 제어권이 프로세스B로 넘어가 같은 데이터를 조작하는 경우를 말한다.
  - 해결 방법 : 프로세스가 커널모드에서 작업 중인 경우에는 CPU 제어권이 다른 프로세스에게 넘어가지 않도록 한다.
    
![img](https://github.com/dilmah0203/TIL/blob/main/Image/race%20condition2.png)

- **CPU가 여러개 있는 멀티 프로세서 환경에서 공유 메모리 내의 커널 데이터에 접근할 경우**
  - 멀티프로세스 환경에서 2개의 CPU가 동시에 커널 내부의 공유 데이터에 접근하여 조작하는 경우에 발생할 수 있다.
  - 해결 방법 : 커널 내부에 있는 각 공유 데이터에 접근할 때마다 그 데이터에 대해 lock을 걸어 접근못하게 하면 해결할 수 있다.

![img](https://github.com/dilmah0203/TIL/blob/main/Image/race%20condition3.png)
 
## Critical Section(임계 구역)

**임계 구역**은 **경쟁상태가 발생할 수 있는 특정 부분**을 말한다. 즉, 공유 데이터에 접근하는 코드 부분을 말한다. 임계 구역으로 인해 발생하는 문제들을 해결하기 위해서는 다음 조건들을 만족해야 한다. 

- Mutual Exclusion(상호 배제)
  - 이미 한 프로세스가 임계 구역에서 작업 중이면 다른 모든 프로세스는 임계 구역에 진입하면 안 된다.
- Progress(진행)
  - 아무도 임계 구역에 있지 않은 상태에서, 임계에 진입하고자 하는 프로세스가 있으면 진입할 수 있어야 한다. 
- Bounded Waiting(한정 대기)
  - 프로세스가 임계 구역에 들어가기 위해 요청한 후부터 그 요청이 허용될 때까지 다른 프로세스들이 임계 구역에 들어가는 횟수에 한계가 있어야 한다.
  - 쉽게 말해, 임계 구역에 진입하려는 프로세스가 무한정 기다려서는 안 된다.
 
## [Semaphores(세마포어)](https://github.com/dilmah0203/TIL/blob/main/OS/Mutex%20vs%20Semaphore.md])

## [Deadlock](https://github.com/dilmah0203/TIL/blob/main/OS/Deadlock.md)

둘 이상의 프로세스가 서로가 가진 자원을 기다리며 block되어 더 이상 진행이 될 수 없는 상태

## Logical vs Physical Address

- Logical Address(=virtual address)
  - 프로세스마다 독립적으로 가지는 주소 공간
  - 각 프로세스마다 0번지부터 시작
  - CPU가 보는 주소는 logical address임 
- Physical Address
  - 메모리에 실제 올라가는 위치

- 주소 바인딩 : 주소를 결정하는 것
  - Symbolic Address(변수이름, 함수이름) → Logical Address → Physical Address

> 그렇다면 논리 주소가 물리적인 주소로 결정되는 시점이 언제인가?

### 주소 바인딩(Address Binding) - 물리적인 메모리가 결정되는 시점

- Compile time Binding → 현대의 컴퓨터 시스템에서는 거의 사용하지 않음
  - 물리적 메모리 주소가 컴파일 시 알려짐
  - 시작 위치 변경 시 재 컴파일
  - 컴파일러 코드는 절대코드(absolute code)생성
- Load time Binding
  - 실행이 시작 되서 메모리에 올라갈 때
  - Loader의 책임하에 물리적 메모리 주소 부여
  - 컴파일러가 재배치 가능 코드(relocatalbe code)를 생성한 경우 가능
- Execution time Binding(Runtime Binding)
  - 수행이 시작된 이후에도 프로세스의 메모리 상 위치를 옮길 수 있음(실행되는 도중 주소가 변경 될 수 있음)
  - CPU가 주소를 참조할 때마다 binding을 점검(address mapping table)
  - 하드웨어적인 지원이 필요ex) base and limit registers, MMU
    
## MMU(Memory-Management Unit)

- Logical Address를 Physical Address로 맵핑해 주는 Hardware Device
  - MMU Scheme: 사용자 프로세스가 CPU에서 수행되며 생성해내는 모든 주소값에 대해 base register(=relocation register)의 값을 더한다.
  - limit register: 프로세스의 논리적 주소 범위 정보 저장
  - relocation register: 접근할 수 있는 물리적 메모리 주소의 최소값
  - 사용자 프로그램은 Logical Address만을 다루며, 실제 Physical Address를 볼 수 없으며 알 필요가 없다.
 
## Dynamic Loading

- 프로세스 전체를 메모리에 미리 다 올리는 것이 아니라 해당 루틴이 불려질 때 load 하는 것
- memory utilization의 향상
- 가끔씩 사용되는 많은 양의 코드의 경우 유용(ex. 오류 처리 루틴)
- 운영체제의 특별한 지원 없이 프로그램 자체에서 구현가능(OS가 라이브러리를 통해 지원 가능)
- Loading의 의미 → 메모리로 올리는 것
- 주의: 운영체제가 관리하는 프로세스가 메모리에 올라갔다 다시 내려가는 동작(페이징 기법)이랑은 본질적으로 다름 → 하지만 요즘에는 용어를 혼용하기도 함

## Overlays

- 메모리에 프로세스의 부분 중 실제 필요한 정보만을 올리는 것
- 프로세스의 크기가 메모리보다 클 때 유용
- 운영체제의 지원 없이 사용자에 의해 구현
- 작은 공간의 메모리를 사용하던 초창기 시스템에서 수작업으로 프로그래머가 구현
  - “Manual Overlay”라고도 일컫음
- 프로그래밍이 매우 복잡

## Swapping

- 프로세스 전체를 일시적으로 메모리에서 backing store로 쫓아내는 것
- Backing store(swap Area): Disk
  - 많은 사용자의 프로세스 이미지를 담을 만큼 충분히 빠르고 큰 저장공간
- Swap in / Swap out
  - 일반적으로 중기 스케줄러(swapper)에 의해 swap out시킬 프로세스 선정
  - priority based CPU scheduling algorithm
    - priority가 낮은 프로세스를 swapped out 시킴
    - priority가 높은 프로세스를 swapped in 시킴
  - Compile time 혹은 load time binding에서는 원래 메모리 위치로 swap in을 해야함(그렇기 때문에 Runtime Binding에서의 효율이 더 좋다 → 빈 메모리 영역 아무 곳에나 올릴 수 있으므로)
  - swap time은 프로그램 전체를 스왑하는 큰 작업이기에, 대부분 transfer time(swap 되는 대상의 양에 비례하는 시간 ↔ seek time)이 차지



